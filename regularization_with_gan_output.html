<!DOCTYPE html>
<html lang="zh">
<head>
<meta charset="UTF-8">
<link rel="alternate"
      type="application/rss+xml"
      href="https://lampze.github.io/rss.xml"
      title="RSS feed for https://lampze.github.io/">
<title>正则化对 GAN 输出结果的影响</title>
<meta  name="author" content="lampze" />
      <link href= "static/style.css" rel="stylesheet" type="text/css" />
      <link href= "static/org.css" rel="stylesheet" type="text/css" />
      <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>
      <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <meta http-equiv="content-type" content="application/xhtml+xml; charset=UTF-8" />
      <meta name="viewport" content="initial-scale=1,width=device-width,minimum-scale=1"></head>
<body>
<div id="preamble" class="status"><div class="header">
        <a href="https://lampze.github.io">lampze's Blog</a>
      </div></div>
<div id="content">
<div class="post-date">2021-08-21</div><h1 class="post-title"><a href="https://lampze.github.io/regularization_with_gan_output.html">正则化对 GAN 输出结果的影响</a></h1>

<div id="outline-container-org41c7235" class="outline-2">
<h2 id="org41c7235">前言</h2>
<div class="outline-text-2" id="text-org41c7235">
<p>
在我尝试使用正则化解决 <code>GAN</code> 模式崩溃的问题时，我发现了一个有意思的现象。我给模型添加了 <code>L2</code> 正则项后，生成的图片比以往要模糊许多，所以我决定测试一下，模糊是不是由 <code>L2</code> 导致的。<br>
</p>
</div>
</div>
<div id="outline-container-org026b827" class="outline-2">
<h2 id="org026b827">测试</h2>
<div class="outline-text-2" id="text-org026b827">
<p>
本模型除了 <code>L1</code> 、 <code>L2</code> 、 <code>Dropout</code> 还使用了其他的优化方法， <code>LayerNorm</code> 、 <code>GELU</code> 、 <code>Adam</code> 。每种模型的训练次数相同，没有给图片加标签，让模式崩溃的效果更明显些。<br>
</p>
</div>
<div id="outline-container-orga7a63b8" class="outline-3">
<h3 id="orga7a63b8">基础代码</h3>
<div class="outline-text-3" id="text-orga7a63b8">
<p>
后面的测试都是基于这份代码之上修改，只放了关键的模型定义与训练代码。<br>
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">class</span> <span style="font-weight: bold;">Discriminator</span>(nn.Module):
    <span style="font-weight: bold;">def</span> <span style="font-weight: bold;">__init__</span>(<span style="font-weight: bold;">self</span>):
        <span style="font-weight: bold;">super</span>().__init__()

        <span style="font-weight: bold;">self</span>.model = nn.Sequential(
            nn.Flatten(),
            nn.Linear(<span style="color: #8a3b3c; font-weight: bold;">28</span> * <span style="color: #8a3b3c; font-weight: bold;">28</span>, <span style="color: #8a3b3c; font-weight: bold;">200</span>),
            nn.GELU(),
            nn.LayerNorm(<span style="color: #8a3b3c; font-weight: bold;">200</span>),
            nn.Linear(<span style="color: #8a3b3c; font-weight: bold;">200</span>, <span style="color: #8a3b3c; font-weight: bold;">1</span>),
            nn.Sigmoid(),
        )
        <span style="font-weight: bold;">self</span>.loss_function = nn.BCELoss()
        <span style="font-weight: bold;">self</span>.optimiser = torch.optim.Adam(
            <span style="font-weight: bold;">self</span>.parameters(), lr=<span style="color: #8a3b3c; font-weight: bold;">0.0001</span>
        )
        <span style="font-weight: bold;">self</span>.progress = []
        <span style="font-weight: bold;">pass</span>

    <span style="font-weight: bold;">def</span> <span style="font-weight: bold;">forward</span>(<span style="font-weight: bold;">self</span>, inputs):
        <span style="font-weight: bold;">return</span> <span style="font-weight: bold;">self</span>.model(inputs).reshape(<span style="color: #8a3b3c; font-weight: bold;">1</span>)

    <span style="font-weight: bold;">def</span> <span style="font-weight: bold;">train</span>(<span style="font-weight: bold;">self</span>, inputs, targets):
        <span style="color: #383a42;">outputs</span> = <span style="font-weight: bold;">self</span>.forward(inputs)
        <span style="color: #383a42;">loss</span> = <span style="font-weight: bold;">self</span>.loss_function(outputs, targets)
        <span style="font-weight: bold;">self</span>.optimiser.zero_grad()
        loss.backward()
        <span style="font-weight: bold;">self</span>.optimiser.step()
        <span style="font-weight: bold;">pass</span>


<span style="font-weight: bold;">class</span> <span style="font-weight: bold;">Generator</span>(nn.Module):
    <span style="font-weight: bold;">def</span> <span style="font-weight: bold;">__init__</span>(<span style="font-weight: bold;">self</span>):
        <span style="font-weight: bold;">super</span>().__init__()

        <span style="font-weight: bold;">self</span>.model = nn.Sequential(
            nn.Linear(<span style="color: #8a3b3c; font-weight: bold;">200</span>, <span style="color: #8a3b3c; font-weight: bold;">400</span>),
            nn.GELU(),
            nn.LayerNorm(<span style="color: #8a3b3c; font-weight: bold;">400</span>),
            nn.Linear(<span style="color: #8a3b3c; font-weight: bold;">400</span>, <span style="color: #8a3b3c; font-weight: bold;">28</span> * <span style="color: #8a3b3c; font-weight: bold;">28</span>),
            nn.Sigmoid(),
        )
        <span style="font-weight: bold;">self</span>.optimiser = torch.optim.Adam(
            <span style="font-weight: bold;">self</span>.parameters(), lr=<span style="color: #8a3b3c; font-weight: bold;">0.0001</span>
        )
        <span style="font-weight: bold;">self</span>.progress = []
        <span style="font-weight: bold;">pass</span>

    <span style="font-weight: bold;">def</span> <span style="font-weight: bold;">forward</span>(<span style="font-weight: bold;">self</span>, inputs):
        <span style="font-weight: bold;">return</span> <span style="font-weight: bold;">self</span>.model(inputs)

    <span style="font-weight: bold;">def</span> <span style="font-weight: bold;">train</span>(<span style="font-weight: bold;">self</span>, D, inputs, targets):
        <span style="color: #383a42;">g_output</span> = <span style="font-weight: bold;">self</span>.forward(inputs)
        <span style="color: #383a42;">d_output</span> = D.forward(g_output.reshape(<span style="color: #8a3b3c; font-weight: bold;">1</span>, <span style="color: #8a3b3c; font-weight: bold;">28</span>, <span style="color: #8a3b3c; font-weight: bold;">28</span>))
        <span style="color: #383a42;">loss</span> = D.loss_function(d_output, targets)
        <span style="font-weight: bold;">self</span>.optimiser.zero_grad()
        loss.backward()
        <span style="font-weight: bold;">self</span>.optimiser.step()
        <span style="font-weight: bold;">pass</span>

<span style="color: #383a42;">D</span> = Discriminator()
<span style="color: #383a42;">G</span> = Generator()

<span style="font-weight: bold;">for</span> epoch <span style="font-weight: bold;">in</span> <span style="font-weight: bold;">range</span>(<span style="color: #8a3b3c; font-weight: bold;">4</span>):
    <span style="font-weight: bold;">for</span> image_data_tensor, label <span style="font-weight: bold;">in</span> mnist_train:
        D.train(image_data_tensor, torch.tensor([<span style="color: #8a3b3c; font-weight: bold;">1.0</span>]))
        D.train(
            G.forward(generate_random_seed(<span style="color: #8a3b3c; font-weight: bold;">200</span>)).detach().reshape(<span style="color: #8a3b3c; font-weight: bold;">1</span>, <span style="color: #8a3b3c; font-weight: bold;">28</span>, <span style="color: #8a3b3c; font-weight: bold;">28</span>),
            torch.tensor([<span style="color: #8a3b3c; font-weight: bold;">0.0</span>]),
        )
        G.train(D, generate_random_seed(<span style="color: #8a3b3c; font-weight: bold;">200</span>), torch.tensor([<span style="color: #8a3b3c; font-weight: bold;">1.0</span>]))
        <span style="font-weight: bold;">pass</span>
    <span style="font-weight: bold;">pass</span>
</pre>
</div>

<p>
后面的测试只放修改位置的代码。<br>
</p>
</div>
<div id="outline-container-org83c2a5c" class="outline-4">
<h4 id="org83c2a5c">训练结果</h4>
<div class="outline-text-4" id="text-org83c2a5c">

<figure id="org7d0440c">
<img src="./static/img/regularization_with_gan_output/normal.png" alt="normal.png"><br>

</figure>
</div>
</div>
<div id="outline-container-org3987deb" class="outline-4">
<h4 id="org3987deb">评价</h4>
<div class="outline-text-4" id="text-org3987deb">
<p>
有些许的模式崩溃现象，只有几种类型的数字，数字的颗粒感比较严重，不够平滑。<br>
</p>
</div>
</div>
</div>
<div id="outline-container-orge178663" class="outline-3">
<h3 id="orge178663">L1</h3>
<div class="outline-text-3" id="text-orge178663">
<p>
更改训练函数即可<br>
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">def</span> <span style="font-weight: bold;">train</span>(<span style="font-weight: bold;">self</span>, D, inputs, targets):
        <span style="color: #383a42;">g_output</span> = <span style="font-weight: bold;">self</span>.forward(inputs)
        <span style="color: #383a42;">d_output</span> = D.forward(g_output.reshape(<span style="color: #8a3b3c; font-weight: bold;">1</span>, <span style="color: #8a3b3c; font-weight: bold;">28</span>, <span style="color: #8a3b3c; font-weight: bold;">28</span>))
        <span style="color: #383a42;">loss</span> = D.loss_function(d_output, targets)

        <span style="color: #383a42;">l1_loss</span> = <span style="color: #8a3b3c; font-weight: bold;">0</span>
        <span style="font-weight: bold;">for</span> param <span style="font-weight: bold;">in</span> <span style="font-weight: bold;">self</span>.parameters():
            <span style="color: #383a42;">l1_loss</span> += torch.<span style="font-weight: bold;">sum</span>(torch.<span style="font-weight: bold;">abs</span>(param))
            <span style="font-weight: bold;">pass</span>
        <span style="color: #383a42;">loss</span> += <span style="color: #8a3b3c; font-weight: bold;">0.005</span> * l1_loss

        <span style="font-weight: bold;">self</span>.optimiser.zero_grad()
        loss.backward()
        <span style="font-weight: bold;">self</span>.optimiser.step()
        <span style="font-weight: bold;">pass</span>
</pre>
</div>
</div>
<div id="outline-container-org11bac64" class="outline-4">
<h4 id="org11bac64">训练结果</h4>
<div class="outline-text-4" id="text-org11bac64">

<figure id="org69ed754">
<img src="./static/img/regularization_with_gan_output/l1.png" alt="l1.png"><br>

</figure>
</div>
</div>
<div id="outline-container-orgce5f480" class="outline-4">
<h4 id="orgce5f480">评价</h4>
<div class="outline-text-4" id="text-orgce5f480">
<p>
几乎没有可以识别的数字，可能是训练次数不够，但数字可以明显看出比较平滑，也就是那种模糊的效果。<br>
</p>
</div>
</div>
</div>
<div id="outline-container-orgc739e13" class="outline-3">
<h3 id="orgc739e13">L2</h3>
<div class="outline-text-3" id="text-orgc739e13">
<p>
<code>pytorch</code> 的优化器通过参数 <code>weight_decay</code> 可以实现 <code>L2</code> 正则。<br>
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">self</span>.optimiser = torch.optim.Adam(
    <span style="font-weight: bold;">self</span>.parameters(), lr=<span style="color: #8a3b3c; font-weight: bold;">0.0001</span>, weight_decay=<span style="color: #8a3b3c; font-weight: bold;">0.005</span>
)
</pre>
</div>
</div>
<div id="outline-container-org472aa5f" class="outline-4">
<h4 id="org472aa5f">训练结果</h4>
<div class="outline-text-4" id="text-org472aa5f">

<figure id="orgc151496">
<img src="./static/img/regularization_with_gan_output/l2.png" alt="l2.png"><br>

</figure>
</div>
</div>
<div id="outline-container-orgfad5267" class="outline-4">
<h4 id="orgfad5267">评价</h4>
<div class="outline-text-4" id="text-orgfad5267">
<p>
相比 <code>L1</code> 数字周围更加干净，更加清晰一些，但模糊的效果还在，与 <code>L1</code> 的差异不排除随机误差的可能。<br>
</p>
</div>
</div>
</div>
<div id="outline-container-org6292247" class="outline-3">
<h3 id="org6292247">Dropout</h3>
<div class="outline-text-3" id="text-org6292247">
<p>
这个添加一个 <code>Dropout</code> 层即可<br>
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">self</span>.model = nn.Sequential(
    nn.Linear(<span style="color: #8a3b3c; font-weight: bold;">200</span>, <span style="color: #8a3b3c; font-weight: bold;">400</span>),
    nn.Dropout(<span style="color: #8a3b3c; font-weight: bold;">0.5</span>),
    nn.GELU(),
    nn.LayerNorm(<span style="color: #8a3b3c; font-weight: bold;">400</span>),
    nn.Linear(<span style="color: #8a3b3c; font-weight: bold;">400</span>, <span style="color: #8a3b3c; font-weight: bold;">28</span> * <span style="color: #8a3b3c; font-weight: bold;">28</span>),
    nn.Sigmoid(),
)
</pre>
</div>
</div>
<div id="outline-container-orgf72735a" class="outline-4">
<h4 id="orgf72735a">训练结果</h4>
<div class="outline-text-4" id="text-orgf72735a">

<figure id="orgbb66107">
<img src="./static/img/regularization_with_gan_output/dropout.png" alt="dropout.png"><br>

</figure>
</div>
</div>
<div id="outline-container-org62e09e4" class="outline-4">
<h4 id="org62e09e4">评价</h4>
<div class="outline-text-4" id="text-org62e09e4">
<p>
没有了模糊效果，但数字都不成形，可能是训练次数不够。<br>
</p>
</div>
</div>
</div>
<div id="outline-container-org8957b59" class="outline-3">
<h3 id="org8957b59">Dropout + L2</h3>
<div class="outline-text-3" id="text-org8957b59">
</div>
<div id="outline-container-org101b0fa" class="outline-4">
<h4 id="org101b0fa">训练结果</h4>
<div class="outline-text-4" id="text-org101b0fa">

<figure id="org3c05b51">
<img src="./static/img/regularization_with_gan_output/dropout_l2.png" alt="dropout_l2.png"><br>

</figure>
</div>
</div>
<div id="outline-container-org7945142" class="outline-4">
<h4 id="org7945142">评价</h4>
<div class="outline-text-4" id="text-org7945142">
<p>
数字很平滑，但都不成型。<br>
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org0ae6c7f" class="outline-2">
<h2 id="org0ae6c7f">结论</h2>
<div class="outline-text-2" id="text-org0ae6c7f">
<p>
经过我不严谨的实验可以发现， <code>L1</code> 与 <code>L2</code> 正则化生成的图片确实会有模糊的效果，具体的原因可能是因为 <code>L1</code> 会让神经网络的参数矩阵更加稀疏， <code>L2</code> 不会让单个参数过大，也就不会因为一个神经元大范围改变结果，而尖锐的效果就是相邻的像素之间差别过大，故会产生模糊的效果。<br>
</p>
</div>
</div>
<div class="taglist"></div></div>
<div id="postamble" class="status"><center>
         <a rel="license" href="https://creativecommons.org/licenses/by-sa/3.0/"></a><br />
         <span xmlns:dct="https://purl.org/dc/terms/"
               href="https://purl.org/dc/dcmitype/Text"
               property="dct:title"
               rel="dct:type">
           https://lampze.github.io
         </span>
         by
         <a xmlns:cc="https://creativecommons.org/ns#"
              href="https://lampze.github.io"
              property="cc:attributionName"
              rel="cc:attributionURL">
           lampze
         </a>
         is licensed under a
         <a rel="license"
            href="https://creativecommons.org/licenses/by-sa/3.0/">
           Creative Commons Attribution-ShareAlike 3.0 Unported License
         </a>.
       </center>
       <script type="text/javascript" src="static/main.js"></script></div>
</body>
</html>
