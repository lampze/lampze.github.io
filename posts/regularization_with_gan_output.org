:PROPERTIES:
:ID:       06036706-b51b-488d-9ee6-be1e35ea82f9
:END:
#+title: 正则化对 GAN 输出结果的影响
#+date:        <2021-08-21 00:00>
#+options:     H:3 num:nil toc:nil \n:t ::t |:t ^:nil -:nil f:t *:t <:t

* 前言
在我尝试使用正则化解决 =GAN= 模式崩溃的问题时，我发现了一个有意思的现象。我给模型添加了 =L2= 正则项后，生成的图片比以往要模糊许多，所以我决定测试一下，模糊是不是由 =L2= 导致的。
* 测试
本模型除了 =L1= 、 =L2= 、 =Dropout= 还使用了其他的优化方法， =LayerNorm= 、 =GELU= 、 =Adam= 。每种模型的训练次数相同，没有给图片加标签，让模式崩溃的效果更明显些。
** 基础代码
后面的测试都是基于这份代码之上修改，只放了关键的模型定义与训练代码。

#+begin_src python
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()

        self.model = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28 * 28, 200),
            nn.GELU(),
            nn.LayerNorm(200),
            nn.Linear(200, 1),
            nn.Sigmoid(),
        )
        self.loss_function = nn.BCELoss()
        self.optimiser = torch.optim.Adam(
            self.parameters(), lr=0.0001
        )
        self.progress = []
        pass

    def forward(self, inputs):
        return self.model(inputs).reshape(1)

    def train(self, inputs, targets):
        outputs = self.forward(inputs)
        loss = self.loss_function(outputs, targets)
        self.optimiser.zero_grad()
        loss.backward()
        self.optimiser.step()
        pass


class Generator(nn.Module):
    def __init__(self):
        super().__init__()

        self.model = nn.Sequential(
            nn.Linear(200, 400),
            nn.GELU(),
            nn.LayerNorm(400),
            nn.Linear(400, 28 * 28),
            nn.Sigmoid(),
        )
        self.optimiser = torch.optim.Adam(
            self.parameters(), lr=0.0001
        )
        self.progress = []
        pass

    def forward(self, inputs):
        return self.model(inputs)

    def train(self, D, inputs, targets):
        g_output = self.forward(inputs)
        d_output = D.forward(g_output.reshape(1, 28, 28))
        loss = D.loss_function(d_output, targets)
        self.optimiser.zero_grad()
        loss.backward()
        self.optimiser.step()
        pass

D = Discriminator()
G = Generator()

for epoch in range(4):
    for image_data_tensor, label in mnist_train:
        D.train(image_data_tensor, torch.tensor([1.0]))
        D.train(
            G.forward(generate_random_seed(200)).detach().reshape(1, 28, 28),
            torch.tensor([0.0]),
        )
        G.train(D, generate_random_seed(200), torch.tensor([1.0]))
        pass
    pass
#+end_src

后面的测试只放修改位置的代码。
*** 训练结果
#+attr_org: :width 500
[[./static/img/regularization_with_gan_output/normal.png]]
*** 评价
有些许的模式崩溃现象，只有几种类型的数字，数字的颗粒感比较严重，不够平滑。
** L1
更改训练函数即可
#+begin_src python
def train(self, D, inputs, targets):
        g_output = self.forward(inputs)
        d_output = D.forward(g_output.reshape(1, 28, 28))
        loss = D.loss_function(d_output, targets)

        l1_loss = 0
        for param in self.parameters():
            l1_loss += torch.sum(torch.abs(param))
            pass
        loss += 0.005 * l1_loss

        self.optimiser.zero_grad()
        loss.backward()
        self.optimiser.step()
        pass
#+end_src
*** 训练结果
#+attr_org: :width 500
[[./static/img/regularization_with_gan_output/l1.png]]
*** 评价
几乎没有可以识别的数字，可能是训练次数不够，但数字可以明显看出比较平滑，也就是那种模糊的效果。
** L2
=pytorch= 的优化器通过参数 =weight_decay= 可以实现 =L2= 正则。
#+begin_src python
self.optimiser = torch.optim.Adam(
    self.parameters(), lr=0.0001, weight_decay=0.005
)
#+end_src
*** 训练结果
#+attr_org: :width 500
[[./static/img/regularization_with_gan_output/l2.png]]
*** 评价
相比 =L1= 数字周围更加干净，更加清晰一些，但模糊的效果还在，与 =L1= 的差异不排除随机误差的可能。
** Dropout
这个添加一个 =Dropout= 层即可
#+begin_src python
self.model = nn.Sequential(
    nn.Linear(200, 400),
    nn.Dropout(0.5),
    nn.GELU(),
    nn.LayerNorm(400),
    nn.Linear(400, 28 * 28),
    nn.Sigmoid(),
)
#+end_src
*** 训练结果
#+attr_org: :width 500
[[./static/img/regularization_with_gan_output/dropout.png]]
*** 评价
没有了模糊效果，但数字都不成形，可能是训练次数不够。
** Dropout + L2
*** 训练结果
#+attr_org: :width 500
[[./static/img/regularization_with_gan_output/dropout_l2.png]]
*** 评价
数字很平滑，但都不成型。
* 结论
经过我不严谨的实验可以发现， =L1= 与 =L2= 正则化生成的图片确实会有模糊的效果，具体的原因可能是因为 =L1= 会让神经网络的参数矩阵更加稀疏， =L2= 不会让单个参数过大，也就不会因为一个神经元大范围改变结果，而尖锐的效果就是相邻的像素之间差别过大，故会产生模糊的效果。
